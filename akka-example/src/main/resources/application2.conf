akka {
  actor {
    provider = "cluster"
  

loggers = ["akka.event.slf4j.Slf4jLogger"]
 loglevel = "INFO"
    stdout-loglevel = "DEBUG"
      logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
    
  }
  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 2552
    }
  }


  persistence {

    ##   journal {
    ##     plugin = "akka.persistence.journal.leveldb"
    ##     auto-start-journals = ["akka.persistence.journal.leveldb"]

    ##   }

    snapshot-store {
      plugin = "akka.persistence.snapshot-store.local"
      auto-start-snapshot-stores = ["akka.persistence.snapshot-store.local"]
    }
  
  }


  cluster {
    quarantine-removed-node-after = 5s

    down-removal-margin = 5s

    seed-nodes = [
      "akka.tcp://ClusterSystem@127.0.0.1:2551",
      "akka.tcp://ClusterSystem@127.0.0.1:2552",
      "akka.tcp://ClusterSystem@127.0.0.1:2553"
      ]
    min-nr-of-members = 1

    singleton{
      # When a node is becoming oldest it sends hand-over request to previous oldest,
      # that might be leaving the cluster. This is retried with this interval until
      # the previous oldest confirms that the hand over has started or the previous
      # oldest member is removed from the cluster (+ akka.cluster.down-removal-margin).
      hand-over-retry-interval = 1s
      # The number of retries are derived from hand-over-retry-interval and
      # akka.cluster.down-removal-margin (or ClusterSingletonManagerSettings.removalMargin),
      # but it will never be less than this property.
      min-number-of-hand-over-retries = 10
    }
    # auto downing is NOT safe for production deployments.
    # you may want to use it during development, read more about it in the docs.
    #
    # auto-down-unreachable-after = 10s

  }
}

akka.cluster.downing-provider-class = com.ajjpj.simpleakkadowning.SimpleAkkaDowningProvider
simple-akka-downing {
  # Time margin after which shards or singletons that belonged to a downed/removed
  #  partition are created in surviving partition. The purpose of this margin is that
  #  in case of a network partition the persistent actors in the non-surviving partitions
  #  must be stopped before corresponding persistent actors are started somewhere else.
  #
  # This margin should be picked based on cluster size, a larger number of nodes introducing
  #  more variance in timing.
  #
  # Disable with "off" or specify a duration to enable.
  #
  # See akka.cluster.down-removal-margin
  down-removal-margin = 10s

  # Time margin after which unreachable nodes in a stable cluster state (i.e. no nodes changed
  #  their membership state or their reachability) are treated as permanently unreachable, and
  #  the split-brain resolution strategy kicks in.
  stable-after = 5s

  # The active strategy is one of static-quorum, keep-majority and keep-oldest. It is triggered
  #  after the cluster configuration has been stable for an interval of 'stable-after'.
  #
  # static-quorum defines a fixed number of nodes, and a network partition must have at least
  #  this number of reachable nodes (in a given role, if that is specified) in order to be allowed
  #  to survive. If the quorum size is picked bigger than half the maximum number of cluster nodes,
  #  this strategy is completely robust. It does not however work well with a dynamically growing
  #  (or shrinking) cluster.
  #
  # keep-majority uses the number of cluster nodes as the baseline and requires a network partition
  #  to have more than half that number of (reachable) nodes in order to be allowed to survive. This
  #  fully supports elastically growing and shrinking clusters, but there are rare race conditions
  #  that can lead to both partitions to be downed or - potentially worse - both partitions to survive.
  #
  # keep-oldest requires the oldest member to be part of a partition for it to survive. This can be
  #  useful since the oldest node is where cluster singletons are running, so this strategy does not
  #  singletons to be migrated and restarted. It reliably prevents split brain, but it can lead to
  #  a situation where 2 nodes survive and 25 nodes are downed. To deal with the pathological special
  #  case that the oldest node is in a network partition of its own, the flag 'down-if-alone' can be
  #  used to specify the oldest node if it is all by itself.
  active-strategy = static-quorum

  # If initial cluster startup delay causes network partitions to be detected, setting
  #  akka.cluster.min-nr-or-members to the value of quorum-size can delay checks
  static-quorum {
    # minimum number of nodes that the cluster must have
    quorum-size = 2

    # if the 'role' is defined the decision is based only on members with that 'role'
    role = ""
  }

  keep-majority {
    role = ""
  }

  keep-oldest {
    # if on, activates special treatment for the situation that the oldest node is the only node to
    #  be split off, causing it to be downed and the rest of the cluster to survive.
    down-if-alone = on
  }
}



# Enable metrics extension in akka-cluster-metrics.
akka.extensions=["akka.cluster.metrics.ClusterMetricsExtension"]

# Sigar native library extract location during tests.
# Note: use per-jvm-instance folder when running multiple jvm on one host.
akka.cluster.metrics.native-library-extract-folder=${user.dir}/target/native